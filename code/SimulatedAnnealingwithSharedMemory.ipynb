{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8mk9mCcy7nl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from multiprocessing import Pool, shared_memory\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xTxTl-t7yzJm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Helper functions for categorical encoding\n",
        "def create_category_mapping(data_column):\n",
        "    \"\"\"Map string categories to integers\"\"\"\n",
        "    categories = np.unique(data_column)\n",
        "    return {cat: i for i, cat in enumerate(categories)}\n",
        "\n",
        "def encode_column(data_column, mapping):\n",
        "    \"\"\"Convert string column to numeric codes\"\"\"\n",
        "    return np.array([mapping[val] for val in data_column], dtype=np.int8)\n",
        "\n",
        "def decode_column(encoded_column, mapping):\n",
        "    \"\"\"Convert numeric codes back to strings\"\"\"\n",
        "    inv_mapping = {v: k for k, v in mapping.items()}\n",
        "    return np.array([inv_mapping[val] for val in encoded_column])\n",
        "\n",
        "# Main worker function (NumPy only)\n",
        "def worker_function(args):\n",
        "    \"\"\"Worker function using only NumPy\"\"\"\n",
        "    shm_name, shape, dtype, col_mappings, criteria, params = args\n",
        "    temp, cooling_rate, iterations = params\n",
        "\n",
        "    # Access shared memory\n",
        "    existing_shm = shared_memory.SharedMemory(name=shm_name)\n",
        "    try:\n",
        "        # Create numpy array view of shared memory\n",
        "        data_array = np.ndarray(shape, dtype=dtype, buffer=existing_shm.buf)\n",
        "\n",
        "        # Initialize solution\n",
        "        current_pop = initialize_population_numpy(data_array, col_mappings, criteria)\n",
        "        current_cost = calculate_cost_numpy(current_pop, col_mappings, criteria)\n",
        "\n",
        "        # Annealing process\n",
        "        for _ in range(iterations):\n",
        "            candidate_pop = current_pop.copy()\n",
        "            candidate_pop = perturb_population_numpy(candidate_pop, data_array, col_mappings, criteria)\n",
        "            candidate_cost = calculate_cost_numpy(candidate_pop, col_mappings, criteria)\n",
        "\n",
        "            if (candidate_cost < current_cost or\n",
        "                np.random.random() < np.exp(-(candidate_cost - current_cost)/temp)):\n",
        "                current_pop = candidate_pop\n",
        "                current_cost = candidate_cost\n",
        "\n",
        "            temp *= cooling_rate\n",
        "\n",
        "        return current_pop\n",
        "    finally:\n",
        "        existing_shm.close()\n",
        "\n",
        "def initialize_population_numpy(data, col_mappings, criteria):\n",
        "    \"\"\"Create initial population using NumPy\"\"\"\n",
        "    if criteria['method'] == 'stratified':\n",
        "        # Get group column indices\n",
        "        group_cols = [i for i, col in enumerate(col_mappings)\n",
        "                     if col['name'] in criteria['groupby_cols']]\n",
        "\n",
        "        # Find unique group combinations\n",
        "        group_values = data[:, group_cols]\n",
        "        unique_groups = np.unique(group_values, axis=0)\n",
        "\n",
        "        # Sample from each group\n",
        "        samples = []\n",
        "        samples_per_group = max(1, criteria['sample_size'] // len(unique_groups))\n",
        "\n",
        "        for group in unique_groups:\n",
        "            mask = np.all(group_values == group, axis=1)\n",
        "            group_data = data[mask]\n",
        "            if len(group_data) > 0:\n",
        "                selected = group_data[np.random.choice(\n",
        "                    len(group_data),\n",
        "                    size=min(len(group_data), samples_per_group),\n",
        "                    replace=True\n",
        "                )]\n",
        "                samples.append(selected)\n",
        "\n",
        "        return np.vstack(samples)\n",
        "    else:  # Random sampling\n",
        "        indices = np.random.choice(len(data), size=criteria['sample_size'], replace=True)\n",
        "        return data[indices]\n",
        "\n",
        "def perturb_population_numpy(population, data, col_mappings, criteria):\n",
        "    \"\"\"Modify population through random perturbations\"\"\"\n",
        "    n_changes = max(1, int(len(population) * criteria['perturb_rate']))\n",
        "\n",
        "    for _ in range(n_changes):\n",
        "        idx = np.random.randint(len(population))\n",
        "\n",
        "        if criteria['method'] == 'stratified':\n",
        "            # Find similar records\n",
        "            group_cols = [i for i, col in enumerate(col_mappings)\n",
        "                         if col['name'] in criteria['groupby_cols']]\n",
        "            mask = np.all(\n",
        "                data[:, group_cols] == population[idx, group_cols],\n",
        "                axis=1\n",
        "            )\n",
        "            candidates = data[mask]\n",
        "        else:\n",
        "            candidates = data\n",
        "\n",
        "        if len(candidates) > 0:\n",
        "            population[idx] = candidates[np.random.choice(len(candidates))]\n",
        "\n",
        "    return population\n",
        "\n",
        "def calculate_cost_numpy(population, col_mappings, criteria):\n",
        "    \"\"\"Calculate cost using NumPy\"\"\"\n",
        "    if criteria['method'] == 'stratified':\n",
        "        group_cols = [i for i, col in enumerate(col_mappings)\n",
        "                     if col['name'] in criteria['groupby_cols']]\n",
        "\n",
        "        # Count group occurrences\n",
        "        unique_groups, counts = np.unique(\n",
        "            population[:, group_cols],\n",
        "            axis=0,\n",
        "            return_counts=True\n",
        "        )\n",
        "\n",
        "        # Calculate proportions\n",
        "        actual_proportions = counts / counts.sum()\n",
        "\n",
        "        # Compare to target (assuming target_proportions is pre-aligned)\n",
        "        target = np.array([criteria['target_proportions'][tuple(group)]\n",
        "                         for group in unique_groups])\n",
        "        return np.mean((actual_proportions - target) ** 2)\n",
        "    else:\n",
        "        # Maximize diversity (count unique values)\n",
        "        return -sum(len(np.unique(population[:, i])) for i in range(population.shape[1]))\n",
        "\n",
        "def generate_populations(original_data, criteria_list, n_processes=None):\n",
        "    \"\"\"Generate synthetic populations in parallel\"\"\"\n",
        "    if n_processes is None:\n",
        "        n_processes = min(len(criteria_list), os.cpu_count())\n",
        "\n",
        "    # Convert dictionary to arrays and encode categoricals\n",
        "    col_mappings = []\n",
        "    encoded_columns = []\n",
        "    for col_name, col_data in original_data.items():\n",
        "        col_data = np.array(col_data)\n",
        "        if col_data.dtype == object:  # String data\n",
        "            mapping = create_category_mapping(col_data)\n",
        "            encoded = encode_column(col_data, mapping)\n",
        "            col_mappings.append({'name': col_name, 'mapping': mapping})\n",
        "        else:\n",
        "            encoded = col_data\n",
        "            col_mappings.append({'name': col_name, 'mapping': None})\n",
        "        encoded_columns.append(encoded)\n",
        "\n",
        "    # Create combined numpy array\n",
        "    data_array = np.column_stack(encoded_columns)\n",
        "\n",
        "    # Create shared memory block\n",
        "    shm = shared_memory.SharedMemory(create=True, size=data_array.nbytes)\n",
        "    try:\n",
        "        shared_array = np.ndarray(data_array.shape, dtype=data_array.dtype, buffer=shm.buf)\n",
        "        np.copyto(shared_array, data_array)\n",
        "\n",
        "        # Prepare worker arguments\n",
        "        common_params = (1000.0, 0.95, 1000)  # temp, cooling_rate, iterations\n",
        "        args_list = [(\n",
        "            shm.name,\n",
        "            data_array.shape,\n",
        "            data_array.dtype,\n",
        "            col_mappings,\n",
        "            criteria,\n",
        "            common_params\n",
        "        ) for criteria in criteria_list]\n",
        "\n",
        "        # Execute in parallel\n",
        "        with Pool(n_processes) as pool:\n",
        "            results = pool.map(worker_function, args_list)\n",
        "\n",
        "        # Decode results back to original format\n",
        "        decoded_results = []\n",
        "        for result in results:\n",
        "            decoded = {}\n",
        "            for i, col in enumerate(col_mappings):\n",
        "                if col['mapping'] is not None:\n",
        "                    decoded[col['name']] = decode_column(result[:, i], col['mapping'])\n",
        "                else:\n",
        "                    decoded[col['name']] = result[:, i]\n",
        "            decoded_results.append(decoded)\n",
        "\n",
        "        return decoded_results\n",
        "    finally:\n",
        "        shm.close()\n",
        "        shm.unlink()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msSnUDARzAhD",
        "outputId": "20bcab0f-2594-49d2-9a35-45f797ba1fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Population 1:\n",
            "age: ['66' '30' '57' '26' '22']...\n",
            "sex: ['F' 'F' 'F' 'F' 'F']...\n",
            "income: ['58481' '51530' '67632' '32277' '65380']...\n",
            "employment: ['employed' 'employed' 'employed' 'employed' 'employed']...\n",
            "Total population 200\n",
            "\n",
            "Population 2:\n",
            "age: ['69' '66' '68' '49' '47']...\n",
            "sex: ['M' 'M' 'M' 'M' 'F']...\n",
            "income: ['45924' '43400' '27278' '21177' '61238']...\n",
            "employment: ['employed' 'employed' 'employed' 'employed' 'student']...\n",
            "Total population 300\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "\n",
        "# Sample data generation\n",
        "rng = np.random.default_rng(42)\n",
        "size = 1000\n",
        "\n",
        "original_data = {\n",
        "    'age': rng.integers(18, 70, size),\n",
        "    'sex': rng.choice(['M', 'F'], size),\n",
        "    'income': rng.normal(50000, 15000, size).astype(int),\n",
        "    'employment': rng.choice(\n",
        "        ['employed', 'unemployed', 'student', 'retired'],\n",
        "        size,\n",
        "        p=[0.6, 0.1, 0.2, 0.1]\n",
        "    )\n",
        "}\n",
        "\n",
        "# Define criteria\n",
        "criteria_list = [\n",
        "    {\n",
        "        'method': 'stratified',\n",
        "        'groupby_cols': ['sex', 'employment'],\n",
        "        'target_proportions': {\n",
        "            ('M', 'employed'): 0.3,\n",
        "            ('M', 'unemployed'): 0.1,\n",
        "            ('M', 'student'): 0.1,\n",
        "            ('M', 'retired'): 0.05,\n",
        "            ('F', 'employed'): 0.3,\n",
        "            ('F', 'unemployed'): 0.05,\n",
        "            ('F', 'student'): 0.05,\n",
        "            ('F', 'retired'): 0.05\n",
        "        },\n",
        "        'sample_size': 200,\n",
        "        'perturb_rate': 0.05\n",
        "    },\n",
        "    {\n",
        "        'method': 'random',\n",
        "        'sample_size': 300,\n",
        "        'perturb_rate': 0.1\n",
        "    }\n",
        "]\n",
        "\n",
        "# Generate populations\n",
        "populations = generate_populations(original_data, criteria_list)\n",
        "\n",
        "# Print results\n",
        "for i, pop in enumerate(populations):\n",
        "    print(f\"\\nPopulation {i+1}:\")\n",
        "    for key, values in pop.items():\n",
        "        print(f\"{key}: {values[:5]}...\")\n",
        "    print(f\"Total population {len(values)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0xyHJ-fzFIO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
